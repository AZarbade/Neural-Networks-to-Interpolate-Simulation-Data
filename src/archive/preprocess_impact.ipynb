{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import delu\n",
    "import delu.data\n",
    "\n",
    "# settings\n",
    "device = torch.device('cuda')\n",
    "delu.improve_reproducibility(base_seed=1024)\n",
    "\n",
    "# wandb config\n",
    "config = {\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 32,\n",
    "    \"dropout\": 0.2,\n",
    "    \"train_split\": 0.8,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"patience\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import delu\n",
    "delu.improve_reproducibility(base_seed=1024)\n",
    "\n",
    "class drdo_data(Dataset):\n",
    "    def __init__(self, dataset, dep_variable, train_split, device,\n",
    "                 all_pp: bool=False, no_pp: bool=False, target_pp: bool=False, feature_pp: bool=False) -> None:\n",
    "        self.train_split = train_split\n",
    "        self.device = device\n",
    "        self.dataset = dataset\n",
    "        self.dep_variable = dep_variable\n",
    "        self.df = pd.read_csv(dataset)\n",
    "        self.X = {}\n",
    "        self.y = {}\n",
    "\n",
    "        y_all = self.df[dep_variable].astype('float32').to_numpy()\n",
    "        X_all = self.df.drop(dep_variable, axis=1).astype('float32').to_numpy()\n",
    "\n",
    "        self.X['train'], self.X['test'], self.y['train'], self.y['test'] = sklearn.model_selection.train_test_split(\n",
    "            X_all, y_all, train_size=train_split, random_state=1024)\n",
    "\n",
    "        self.X['train'], self.X['val'], self.y['train'], self.y['val'] = sklearn.model_selection.train_test_split(\n",
    "            self.X['train'], self.y['train'], train_size=train_split, random_state=1024)\n",
    "        \n",
    "        if all_pp == True:\n",
    "            preprocess = sklearn.preprocessing.QuantileTransformer()\n",
    "            preprocess.fit(self.X['train'])\n",
    "            self.X = {k: torch.tensor(preprocess.transform(v), device=device) for k, v in self.X.items()}\n",
    "            self.y = {k: torch.tensor(v, device=device) for k, v in self.y.items()}\n",
    "            self.y_mean = self.y['train'].mean().item()\n",
    "            self.y_std = self.y['train'].std().item()\n",
    "            self.y = {k: (v - self.y_mean) / self.y_std for k, v in self.y.items()}\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if no_pp == True:\n",
    "            self.X = {k: torch.tensor(v, device=device) for k, v in self.X.items()}\n",
    "            self.y = {k: torch.tensor(v, device=device) for k, v in self.y.items()}\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if target_pp == True:\n",
    "            self.X = {k: torch.tensor(v, device=device) for k, v in self.X.items()}\n",
    "            self.y = {k: torch.tensor(v, device=device) for k, v in self.y.items()}\n",
    "            self.y_mean = self.y['train'].mean().item()\n",
    "            self.y_std = self.y['train'].std().item()\n",
    "            self.y = {k: (v - self.y_mean) / self.y_std for k, v in self.y.items()}\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if feature_pp == True:\n",
    "            preprocess = sklearn.preprocessing.QuantileTransformer()\n",
    "            preprocess.fit(self.X['train'])\n",
    "            self.X = {k: torch.tensor(preprocess.transform(v), device=device) for k, v in self.X.items()}\n",
    "            self.y = {k: torch.tensor(v, device=device) for k, v in self.y.items()}\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X['train'][index], self.y['train'][index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LD</th>\n",
       "      <th>Velocity (km/s)</th>\n",
       "      <th>a (degrees)</th>\n",
       "      <th>$ (degrees)</th>\n",
       "      <th>DI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>90</td>\n",
       "      <td>45</td>\n",
       "      <td>0.01259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LD  Velocity (km/s)  a (degrees)  $ (degrees)       DI\n",
       "0   1             0.25           90           75  0.00007\n",
       "1   1             0.25           90           60  0.00580\n",
       "2   1             0.25           90           45  0.01259"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/SIDI_Full.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pp:\n",
      "tensor([[0.4940, 0.6381, 0.8103, 0.2457],\n",
      "        [0.4940, 0.2257, 0.3589, 0.7447],\n",
      "        [0.0000, 0.3699, 0.4339, 0.4154],\n",
      "        ...,\n",
      "        [0.0000, 0.3699, 0.1216, 0.0000],\n",
      "        [0.4940, 0.0000, 0.7352, 0.2457],\n",
      "        [0.0000, 0.0000, 0.2032, 0.0000]], device='cuda:0')\n",
      "no_pp:\n",
      "tensor([[  2.0000,   1.5000,  60.0000,  15.0000],\n",
      "        [  2.0000,   0.5000, -30.0000,  60.0000],\n",
      "        [  1.0000,   1.0000, -15.0000,  30.0000],\n",
      "        ...,\n",
      "        [  1.0000,   1.0000, -75.0000,   0.0000],\n",
      "        [  2.0000,   0.2500,  45.0000,  15.0000],\n",
      "        [  1.0000,   0.2500, -60.0000,   0.0000]], device='cuda:0')\n",
      "target_pp:\n",
      "tensor([[  2.0000,   1.5000,  60.0000,  15.0000],\n",
      "        [  2.0000,   0.5000, -30.0000,  60.0000],\n",
      "        [  1.0000,   1.0000, -15.0000,  30.0000],\n",
      "        ...,\n",
      "        [  1.0000,   1.0000, -75.0000,   0.0000],\n",
      "        [  2.0000,   0.2500,  45.0000,  15.0000],\n",
      "        [  1.0000,   0.2500, -60.0000,   0.0000]], device='cuda:0')\n",
      "feature_pp:\n",
      "tensor([[0.4940, 0.6381, 0.8103, 0.2457],\n",
      "        [0.4940, 0.2257, 0.3589, 0.7447],\n",
      "        [0.0000, 0.3699, 0.4339, 0.4154],\n",
      "        ...,\n",
      "        [0.0000, 0.3699, 0.1216, 0.0000],\n",
      "        [0.4940, 0.0000, 0.7352, 0.2457],\n",
      "        [0.0000, 0.0000, 0.2032, 0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "all_pp = drdo_data(\n",
    "    dataset='../../data/SIDI_Full.csv',\n",
    "    dep_variable='DI',\n",
    "    train_split=0.8,\n",
    "    device=device,\n",
    "    all_pp=True\n",
    ")\n",
    "no_pp = drdo_data(\n",
    "    dataset='../../data/SIDI_Full.csv',\n",
    "    dep_variable='DI',\n",
    "    train_split=0.8,\n",
    "    device=device,\n",
    "    no_pp=True\n",
    ")\n",
    "target_pp = drdo_data(\n",
    "    dataset='../../data/SIDI_Full.csv',\n",
    "    dep_variable='DI',\n",
    "    train_split=0.8,\n",
    "    device=device,\n",
    "    target_pp=True\n",
    ")\n",
    "feature_pp = drdo_data(\n",
    "    dataset='../../data/SIDI_Full.csv',\n",
    "    dep_variable='DI',\n",
    "    train_split=0.8,\n",
    "    device=device,\n",
    "    feature_pp=True\n",
    ")\n",
    "print(f\"all_pp:\\n{all_pp.X['train']}\")\n",
    "print(f\"no_pp:\\n{no_pp.X['train']}\")\n",
    "print(f\"target_pp:\\n{target_pp.X['train']}\")\n",
    "print(f\"feature_pp:\\n{feature_pp.X['train']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'all_pp': [], 'no_pp': [], 'target_pp': [], 'feature_pp': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.8074\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m valid_rmse \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(val_score[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     56\u001b[0m test_rmse \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(test_score[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m---> 58\u001b[0m losses[\u001b[39m'\u001b[39m\u001b[39mall_pp\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(test_rmse[\u001b[39m'\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Validation score: \u001b[39m\u001b[39m{\u001b[39;00mval_score[\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Test score: \u001b[39m\u001b[39m{\u001b[39;00mtest_score[\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m progress\u001b[39m.\u001b[39mupdate((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m val_score[\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# all_pp\n",
    "import math\n",
    "import rtdl\n",
    "\n",
    "data = all_pp\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=data.X['train'].shape[1],\n",
    "    d_layers=[64,64],\n",
    "    dropout=config['dropout'],\n",
    "    d_out=1,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    torch.optim.AdamW(model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'])\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    pred = model(data.X[part]).squeeze(1)\n",
    "    target = data.y[part]\n",
    "    score = loss_fn(pred, target)\n",
    "    return {\n",
    "        'score': score,\n",
    "        'pred': pred,\n",
    "        'target': target\n",
    "    }\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "batch_size = config['batch_size']\n",
    "train_loader = delu.data.make_index_dataloader(len(data.X['train']), config['batch_size'])\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "progress = delu.ProgressTracker(config['patience'])\n",
    "print(f'Test score before training: {evaluate(\"test\")[\"score\"]:.4f}')\n",
    "\n",
    "n_epochs = config['epochs']\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = data.X['train'][batch_idx]\n",
    "        y_batch = data.y['train'][batch_idx]\n",
    "        loss = loss_fn(model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "\n",
    "    valid_rmse = math.sqrt(val_score['score'].cpu().numpy())\n",
    "    test_rmse = math.sqrt(test_score['score'].cpu().numpy())\n",
    "\n",
    "    losses['all_pp'].append(test_rmse)\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score[\"score\"]:.4f} | Test score: {test_score[\"score\"]:.4f}', end='')\n",
    "    progress.update((-1) * val_score[\"score\"])\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_rmse[\u001b[39m'\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_rmse['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_score['pred'].shape)\n",
    "print(test_score['target'].shape)\n",
    "\n",
    "tmp = pd.DataFrame()\n",
    "tmp['predictions'] = test_score['pred'].cpu().numpy()\n",
    "tmp['targets'] = test_score['target'].cpu().numpy()\n",
    "\n",
    "'''(target - pred)/(target)'''\n",
    "\n",
    "tmp['error'] = (((test_score['target'].cpu().numpy() - test_score['pred'].cpu().numpy()) / test_score['target'].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the window size for the moving average\n",
    "window_size = 33\n",
    "\n",
    "# Calculate the moving average using np.convolve\n",
    "smoothed_predictions = np.convolve(tmp['predictions'], np.ones(window_size)/window_size, mode='same')\n",
    "smoothed_targets = np.convolve(tmp['targets'], np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(smoothed_predictions, label='predictions')\n",
    "plt.plot(smoothed_targets, label='targets')\n",
    "# plt.plot(tmp['error'], label='error')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# Assume tmp['predictions'], tmp['targets'], and tmp['error'] are defined\n",
    "\n",
    "# Define the window size for the moving average\n",
    "window_size = 33\n",
    "\n",
    "# Calculate the moving average using np.convolve\n",
    "smoothed_predictions = np.convolve(tmp['predictions'], np.ones(window_size)/window_size, mode='same')\n",
    "smoothed_targets = np.convolve(tmp['targets'], np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "# Generate smooth curves using make_interp_spline\n",
    "x = np.arange(len(tmp['predictions']))\n",
    "x_smooth = np.linspace(x.min(), x.max(), 1000)  # Adjust the number of points for smoother curve\n",
    "curve_predictions = make_interp_spline(x, smoothed_predictions)(x_smooth)\n",
    "curve_targets = make_interp_spline(x, smoothed_targets)(x_smooth)\n",
    "\n",
    "# Plot the original and smoothed data with smooth curves\n",
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# ax1.plot(tmp['predictions'], label='predictions')\n",
    "# ax1.plot(tmp['targets'], label='targets')\n",
    "ax1.plot(x_smooth, curve_predictions, label='smoothed predictions')\n",
    "ax1.plot(x_smooth, curve_targets, label='smoothed targets')\n",
    "\n",
    "ax1.set_xlabel('Index')\n",
    "ax1.set_ylabel('Value')\n",
    "\n",
    "# Create a secondary y-axis for error\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(tmp['error'], color='red', label='error')\n",
    "ax2.set_ylabel('Error')\n",
    "\n",
    "# Combine the legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_pp\n",
    "import math\n",
    "import rtdl\n",
    "\n",
    "data = no_pp\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=data.X['train'].shape[1],\n",
    "    d_layers=[64,64],\n",
    "    dropout=config['dropout'],\n",
    "    d_out=1,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    torch.optim.AdamW(model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'])\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    pred = model(data.X[part]).squeeze(1)\n",
    "    target = data.y[part]\n",
    "    score = loss_fn(pred, target)\n",
    "    return score\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "batch_size = config['batch_size']\n",
    "train_loader = delu.data.make_index_dataloader(len(data.X['train']), config['batch_size'])\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "progress = delu.ProgressTracker(config['patience'])\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')\n",
    "\n",
    "n_epochs = config['epochs']\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = data.X['train'][batch_idx]\n",
    "        y_batch = data.y['train'][batch_idx]\n",
    "        loss = loss_fn(model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "\n",
    "    valid_rmse = math.sqrt(val_score.cpu().numpy())\n",
    "    test_rmse = math.sqrt(test_score.cpu().numpy())\n",
    "\n",
    "    losses['no_pp'].append(test_rmse['score'])\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_pp\n",
    "import math\n",
    "import rtdl\n",
    "\n",
    "data = target_pp\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=data.X['train'].shape[1],\n",
    "    d_layers=[64,64],\n",
    "    dropout=config['dropout'],\n",
    "    d_out=1,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    torch.optim.AdamW(model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'])\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    pred = model(data.X[part]).squeeze(1)\n",
    "    target = data.y[part]\n",
    "    score = loss_fn(pred, target)\n",
    "    return score\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "batch_size = config['batch_size']\n",
    "train_loader = delu.data.make_index_dataloader(len(data.X['train']), config['batch_size'])\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "progress = delu.ProgressTracker(config['patience'])\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')\n",
    "\n",
    "n_epochs = config['epochs']\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = data.X['train'][batch_idx]\n",
    "        y_batch = data.y['train'][batch_idx]\n",
    "        loss = loss_fn(model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "\n",
    "    valid_rmse = math.sqrt(val_score.cpu().numpy())\n",
    "    test_rmse = math.sqrt(test_score.cpu().numpy())\n",
    "\n",
    "    losses['target_pp'].append(test_rmse['score'])\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_pp\n",
    "import math\n",
    "import rtdl\n",
    "\n",
    "data = feature_pp\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=data.X['train'].shape[1],\n",
    "    d_layers=[64,64],\n",
    "    dropout=config['dropout'],\n",
    "    d_out=1,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    torch.optim.AdamW(model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'])\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    pred = model(data.X[part]).squeeze(1)\n",
    "    target = data.y[part]\n",
    "    score = loss_fn(pred, target)\n",
    "    return score\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "batch_size = config['batch_size']\n",
    "train_loader = delu.data.make_index_dataloader(len(data.X['train']), config['batch_size'])\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "progress = delu.ProgressTracker(config['patience'])\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')\n",
    "\n",
    "n_epochs = config['epochs']\n",
    "for epoch in range(n_epochs):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = data.X['train'][batch_idx]\n",
    "        y_batch = data.y['train'][batch_idx]\n",
    "        loss = loss_fn(model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "\n",
    "    valid_rmse = math.sqrt(val_score.cpu().numpy())\n",
    "    test_rmse = math.sqrt(test_score.cpu().numpy())\n",
    "\n",
    "    losses['feature_pp'].append(test_rmse['score'])\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1) * val_score)\n",
    "    if progress.success:\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(losses['all_pp'], label='all_pp')\n",
    "plt.plot(losses['no_pp'], label='no_pp')\n",
    "plt.plot(losses['target_pp'], label='target_pp')\n",
    "plt.plot(losses['feature_pp'], label='feature_pp')\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('rmse loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e34fafbb8b198028875babf068fcc515154013c29fb5c0213fe99aebdcd4c28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
